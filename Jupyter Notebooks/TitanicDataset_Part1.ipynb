{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project ARI3205 Interpretable AI for Deep Learning Models *(Part 1.2)*\n",
    "---\n",
    "\n",
    "**Name:** Andrea Filiberto Lucas  \n",
    "**ID No:** 0279704L\n",
    "\n",
    "---\n",
    "\n",
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[92m✔\u001b[0m] Library 'tensorflow' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'scikit-learn' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'matplotlib' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'seaborn' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'pandas' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'numpy' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'scipy' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'alibi' is already installed.\n"
     ]
    }
   ],
   "source": [
    "# Check and install required libraries from the libraries.json file\n",
    "import json\n",
    "\n",
    "# Read the libraries from the text file\n",
    "with open('../Libraries/Q1_lib.json', 'r') as file:\n",
    "    libraries = json.load(file)\n",
    "\n",
    "# ANSI escape codes for colored output\n",
    "GREEN = \"\\033[92m\"  # Green text\n",
    "RED = \"\\033[91m\"    # Red text\n",
    "RESET = \"\\033[0m\"   # Reset to default color\n",
    "\n",
    "# Function to check and install libraries\n",
    "def check_and_install_libraries(libraries):\n",
    "    for lib, import_name in libraries.items():\n",
    "        try:\n",
    "            # Attempt to import the library\n",
    "            __import__(import_name)\n",
    "            print(f\"[{GREEN}✔{RESET}] Library '{lib}' is already installed.\")\n",
    "        except ImportError:\n",
    "            # If import fails, try to install the library\n",
    "            print(f\"[{RED}✖{RESET}] Library '{lib}' is not installed. Installing...\")\n",
    "            %pip install {lib}\n",
    "\n",
    "# Execute the function to check and install libraries\n",
    "check_and_install_libraries(libraries)\n",
    "\n",
    "# Import necessary libraries for data analysis and modeling\n",
    "import warnings                                                                     # Disable warnings\n",
    "import pandas as pd                                                                 # Data manipulation and analysis                #type: ignore\n",
    "import numpy as np                                                                  # Numerical computations                        #type: ignore\n",
    "import matplotlib.pyplot as plt                                                     # Data visualization                            #type: ignore\n",
    "import seaborn as sns                                                               # Statistical data visualization                #type: ignore\n",
    "import statsmodels.formula.api as smf                                               # Statistical models                            #type: ignore\n",
    "from sklearn.model_selection import train_test_split                                # Train-test split                              #type: ignore\n",
    "from tensorflow.keras.models import Sequential                                      # Neural network model                          #type: ignore\n",
    "from tensorflow.keras.layers import Dense, Input                                    # Neural network layers                         #type: ignore                                                               \n",
    "from tensorflow.keras.optimizers import Adam                                        # Neural network optimizer                      #type: ignore\n",
    "from sklearn.preprocessing import StandardScaler,  OneHotEncoder                    # Data scaling                                  #type: ignore\n",
    "from sklearn.impute import SimpleImputer                                            # Missing value imputation                      #type: ignore\n",
    "from sklearn.inspection import PartialDependenceDisplay, permutation_importance     # Feature importance                            #type: ignore\n",
    "from alibi.explainers import ALE, plot_ale                                          # ALE plots                                     #type: ignore\n",
    "from sklearn.neural_network import MLPClassifier                                    # Neural network classifier                     #type: ignore\n",
    "from sklearn.metrics import accuracy_score                                          # Model evaluation                              #type: ignore\n",
    "import statsmodels.api as sm                                                        # Statistical models                            #type: ignore\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\") \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information on Titanic Dataset\n",
    "*https://www.kaggle.com/competitions/titanic/data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'../Datasets/Titanic/train.csv' dataset loaded successfully.\n",
      "'../Datasets/Titanic/test.csv' dataset loaded successfully.\n",
      "'../Datasets/Titanic/gender_submission.csv' dataset loaded successfully.\n",
      "\n",
      "Train Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "\n",
      "Train Dataset Statistical Summary:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "Test Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n",
      "None\n",
      "\n",
      "Test Dataset Statistical Summary:\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n",
      "\n",
      "Gender Submission Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Survived     418 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 6.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the filenames\n",
    "train_filename = '../Datasets/Titanic/train.csv'\n",
    "test_filename = '../Datasets/Titanic/test.csv'\n",
    "gender_submission_filename = '../Datasets/Titanic/gender_submission.csv'\n",
    "\n",
    "# Load the datasets\n",
    "try:\n",
    "    train_data = pd.read_csv(train_filename)\n",
    "    test_data = pd.read_csv(test_filename)\n",
    "    gender_submission_data = pd.read_csv(gender_submission_filename)\n",
    "    print(f\"'{train_filename}' dataset loaded successfully.\")\n",
    "    print(f\"'{test_filename}' dataset loaded successfully.\")\n",
    "    print(f\"'{gender_submission_filename}' dataset loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e.filename} was not found. Please ensure it is in the correct directory.\")\n",
    "    exit()\n",
    "except pd.errors.EmptyDataError as e:\n",
    "    print(f\"Error: {e.filename} is empty.\")\n",
    "    exit()\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error: There was a problem parsing {e.filename}. Please check the file format.\")\n",
    "    exit()\n",
    "\n",
    "# Dataset insights\n",
    "print(\"\\nTrain Dataset Overview:\")\n",
    "print(train_data.info())\n",
    "print(\"\\nTrain Dataset Statistical Summary:\")\n",
    "print(train_data.describe())\n",
    "\n",
    "print(\"\\nTest Dataset Overview:\")\n",
    "print(test_data.info())\n",
    "print(\"\\nTest Dataset Statistical Summary:\")\n",
    "print(test_data.describe())\n",
    "\n",
    "print(\"\\nGender Submission Dataset Overview:\")\n",
    "print(gender_submission_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (712, 11)\n",
      "Test data shape: (179, 11)\n"
     ]
    }
   ],
   "source": [
 