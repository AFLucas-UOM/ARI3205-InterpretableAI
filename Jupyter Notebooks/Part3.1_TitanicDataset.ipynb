{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project ARI3205 Interpretable AI for Deep Learning Models *(Part 3.1)*\n",
    "---\n",
    "\n",
    "**Name:** Sean David Muscat \n",
    "\n",
    "**ID No:** 0172004L\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[92m✔\u001b[0m] Library 'tensorflow' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'scikit-learn' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'matplotlib' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'seaborn' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'pandas' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'numpy' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'statsmodels' is already installed.\n"
     ]
    }
   ],
   "source": [
    "# Check and install required libraries from the libraries.json file\n",
    "import json\n",
    "\n",
    "# Read the libraries from the text file\n",
    "with open('../Libraries/Part3.1_Lib.json', 'r') as file:\n",
    "    libraries = json.load(file)\n",
    "\n",
    "# ANSI escape codes for colored output\n",
    "GREEN = \"\\033[92m\"  # Green text\n",
    "RED = \"\\033[91m\"    # Red text\n",
    "RESET = \"\\033[0m\"   # Reset to default color\n",
    "\n",
    "# Function to check and install libraries\n",
    "def check_and_install_libraries(libraries):\n",
    "    for lib, import_name in libraries.items():\n",
    "        try:\n",
    "            # Attempt to import the library\n",
    "            __import__(import_name)\n",
    "            print(f\"[{GREEN}✔{RESET}] Library '{lib}' is already installed.\")\n",
    "        except ImportError:\n",
    "            # If import fails, try to install the library\n",
    "            print(f\"[{RED}✖{RESET}] Library '{lib}' is not installed. Installing...\")\n",
    "            %pip install {lib}\n",
    "\n",
    "# Execute the function to check and install libraries\n",
    "check_and_install_libraries(libraries)\n",
    "\n",
    "# Import necessary libraries for data analysis and modeling\n",
    "import warnings                                                                     # Disable warnings\n",
    "import pandas as pd                                                                 # Data manipulation and analysis                #type: ignore\n",
    "import matplotlib.pyplot as plt                                                     # Data visualization                            #type: ignore\n",
    "import seaborn as sns                                                               # Statistical data visualization                #type: ignore\n",
    "import statsmodels.formula.api as smf                                               # Statistical models                            #type: ignore\n",
    "# Alibi imports for the MNIST example\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(40)  # suppress deprecation messages\n",
    "tf.compat.v1.disable_v2_behavior()  # disable TF2 behaviour as Alibi code still relies on TF1 constructs\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.layers import Dense, Input                                    # Neural network layers                         #type: ignore\n",
    "from tensorflow.keras.models import Sequential                                      # Neural network model                          #type: ignore\n",
    "from sklearn.model_selection import train_test_split                                # Train-test split                              #type: ignore                                                              \n",
    "from tensorflow.keras.optimizers import Adam                                        # Neural network optimizer                      #type: ignore\n",
    "from sklearn.preprocessing import StandardScaler,  OneHotEncoder                    # Data scaling                                  #type: ignore\n",
    "from sklearn.impute import SimpleImputer                                            # Missing value imputation                      #type: ignore\n",
    "from sklearn.neural_network import MLPClassifier                                    # Neural network classifier                     #type: ignore\n",
    "from alibi.explainers import Counterfactual\n",
    "import numpy as np                                                                  # Numerical computations                        #type: ignore\n",
    "\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\") \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'../Datasets/Titanic/train.csv' dataset loaded successfully.\n",
      "'../Datasets/Titanic/test.csv' dataset loaded successfully.\n",
      "'../Datasets/Titanic/gender_submission.csv' dataset loaded successfully.\n",
      "\n",
      "Train Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "\n",
      "Train Dataset Statistical Summary:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "Test Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n",
      "None\n",
      "\n",
      "Test Dataset Statistical Summary:\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n",
      "\n",
      "Gender Submission Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Survived     418 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 6.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the filenames\n",
    "train_filename = '../Datasets/Titanic/train.csv'\n",
    "test_filename = '../Datasets/Titanic/test.csv'\n",
    "gender_submission_filename = '../Datasets/Titanic/gender_submission.csv'\n",
    "\n",
    "# Load the datasets\n",
    "try:\n",
    "    train_data = pd.read_csv(train_filename)\n",
    "    test_data = pd.read_csv(test_filename)\n",
    "    gender_submission_data = pd.read_csv(gender_submission_filename)\n",
    "    print(f\"'{train_filename}' dataset loaded successfully.\")\n",
    "    print(f\"'{test_filename}' dataset loaded successfully.\")\n",
    "    print(f\"'{gender_submission_filename}' dataset loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e.filename} was not found. Please ensure it is in the correct directory.\")\n",
    "    exit()\n",
    "except pd.errors.EmptyDataError as e:\n",
    "    print(f\"Error: {e.filename} is empty.\")\n",
    "    exit()\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error: There was a problem parsing {e.filename}. Please check the file format.\")\n",
    "    exit()\n",
    "\n",
    "# Dataset insights\n",
    "print(\"\\nTrain Dataset Overview:\")\n",
    "print(train_data.info())\n",
    "print(\"\\nTrain Dataset Statistical Summary:\")\n",
    "print(train_data.describe())\n",
    "\n",
    "print(\"\\nTest Dataset Overview:\")\n",
    "print(test_data.info())\n",
    "print(\"\\nTest Dataset Statistical Summary:\")\n",
    "print(test_data.describe())\n",
    "\n",
    "print(\"\\nGender Submission Dataset Overview:\")\n",
    "print(gender_submission_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (712, 11)\n",
      "Test data shape: (179, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load the Titanic dataset\n",
    "train_data = pd.read_csv('../Datasets/Titanic/train.csv')\n",
    "\n",
    "# Preprocessing\n",
    "# Separate features and target\n",
    "y = train_data['Survived']  # Target\n",
    "X = train_data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])  # Features\n",
    "\n",
    "# Handle categorical variables with one-hot encoding\n",
    "categorical_features = ['Sex', 'Embarked']\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "categorical_encoded = one_hot_encoder.fit_transform(X[categorical_features])\n",
    "categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=one_hot_encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# Drop original categorical columns and append the encoded columns\n",
    "X = X.drop(columns=categorical_features)\n",
    "X = pd.concat([X.reset_index(drop=True), categorical_encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Handle missing values with mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X.columns)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the feed-forward neural network\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Define input shape explicitly\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Model - MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (MLPClassifier): 0.800561797752809\n"
     ]
    }
   ],
   "source": [
    "# Train a surrogate model (MLPClassifier)\n",
    "surrogate_model = MLPClassifier(hidden_layer_sizes=(32,), activation='logistic', random_state=1, max_iter=1000).fit(X_train, y_train)\n",
    "print('Accuracy (MLPClassifier): ' + str(surrogate_model.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.1\n",
    "\n",
    "### Set up Counterfactuals\n",
    "\n",
    "We begin by predicting labels on the test set and identifying which samples the model misclassifies. For each misclassified passenger, we record their scaled features and define a prediction function that converts our model’s single sigmoid output into a two-column probability array: [p(died), p(survived)]. Alibi’s counterfactual explainer then searches within specified min/max bounds for a new set of feature values that shifts the model’s predicted outcome (for example, from “died” to “survived”). Finally, we compare these counterfactual features with the originals to see how small changes in attributes like Age or Fare can flip the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrectly predicted samples: 83\n",
      "\n",
      "*** COUNTERFACTUAL #1 ***\n",
      "Sample index: 1, Actual label: 0, Predicted: 1\n",
      "\n",
      "Sample features (scaled):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>-0.369365</td>\n",
       "      <td>0.100109</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.437007</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "      <td>-0.047431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pclass       Age     SibSp     Parch      Fare  Sex_female  Sex_male  \\\n",
       "439 -0.369365  0.100109 -0.474545 -0.473674 -0.437007   -0.737695  0.737695   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  Embarked_nan  \n",
       "439   -0.482043   -0.307562    0.619306     -0.047431  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Counterfactual Explanation ---\n",
      "Original 2-column probability: [[0.43319923 0.5668008 ]]\n",
      "No counterfactual found within the specified parameters.\n",
      "\n",
      "*** COUNTERFACTUAL #2 ***\n",
      "Sample index: 2, Actual label: 0, Predicted: 1\n",
      "\n",
      "Sample features (scaled):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.746389</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "      <td>-0.047431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pclass       Age     SibSp     Parch      Fare  Sex_female  Sex_male  \\\n",
       "840  0.827377 -0.746389 -0.474545 -0.473674 -0.488854   -0.737695  0.737695   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  Embarked_nan  \n",
       "840   -0.482043   -0.307562    0.619306     -0.047431  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:alibi.explainers.counterfactual:No appropriate lambda range found, try decreasing lam_init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Counterfactual Explanation ---\n",
      "Original 2-column probability: [[0.48958385 0.51041615]]\n",
      "No counterfactual found within the specified parameters.\n"
     ]
    }
   ],
   "source": [
    "# 1. Make predictions on the test set\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# 2. Identify misclassified samples\n",
    "incorrect_indices = np.where(y_pred != y_test.values)[0]\n",
    "print(f\"Number of incorrectly predicted samples: {len(incorrect_indices)}\")\n",
    "\n",
    "# Make sure we have at least 2 misclassified samples\n",
    "if len(incorrect_indices) < 2:\n",
    "    print(\"Fewer than 2 misclassified samples found. Cannot generate two counterfactuals.\")\n",
    "else:\n",
    "    #####################################\n",
    "    # LOOP OVER THE FIRST 2 MISCLASSIFIED\n",
    "    #####################################\n",
    "    for i in range(2):  # generate counterfactual for the first two misclassified\n",
    "        print(f\"\\n*** COUNTERFACTUAL #{i+1} ***\")\n",
    "\n",
    "        # 3. Select one misclassified example\n",
    "        sample_idx = incorrect_indices[i]  # pick the i-th misclassified sample\n",
    "        x_test_sample = X_test.iloc[[sample_idx]].values  \n",
    "        actual_label = y_test.values[sample_idx]\n",
    "        print(f\"Sample index: {sample_idx}, Actual label: {actual_label}, Predicted: {y_pred[sample_idx]}\")\n",
    "        print(\"\\nSample features (scaled):\")\n",
    "        display(X_test.iloc[[sample_idx]])\n",
    "\n",
    "        # 4. Define a new predict_fn that outputs [p(died), p(survived)] for each sample\n",
    "        def predict_fn(x: np.ndarray) -> np.ndarray:\n",
    "            if x.ndim == 1:\n",
    "                x = x.reshape(1, -1)\n",
    "            p_survived = model.predict(x).flatten()\n",
    "            p_died = 1.0 - p_survived\n",
    "            return np.vstack([p_died, p_survived]).T\n",
    "\n",
    "        # 5. Determine feature_range from training data\n",
    "        lower_bounds = X_train.min(axis=0).values\n",
    "        upper_bounds = X_train.max(axis=0).values\n",
    "        feature_range = (lower_bounds, upper_bounds)\n",
    "\n",
    "        # 6. Decide on target_proba to 'flip' the original label\n",
    "        desired_proba = 0.8 if actual_label == 0 else 0.2\n",
    "\n",
    "        # 7. Instantiate the Counterfactual explainer\n",
    "        cf_explainer = Counterfactual(\n",
    "            predict_fn=predict_fn,\n",
    "            shape=(1, X_train.shape[1]),\n",
    "            target_proba=desired_proba,\n",
    "            max_iter=1000,\n",
    "            feature_range=feature_range,\n",
    "            lam_init=1e-1,\n",
    "            max_lam_steps=10,\n",
    "            learning_rate_init=1e-2\n",
    "        )\n",
    "\n",
    "        # 8. Generate a counterfactual explanation\n",
    "        explanation = cf_explainer.explain(x_test_sample)\n",
    "\n",
    "        # 9. Print results\n",
    "        print(\"\\n--- Counterfactual Explanation ---\")\n",
    "        print(\"Original 2-column probability:\", predict_fn(x_test_sample))\n",
    "        if explanation.cf is not None:\n",
    "            cf_sample = explanation.cf['X']  # shape => (1, n_features)\n",
    "            print(\"\\nCounterfactual feature values (scaled):\")\n",
    "            display(cf_sample)\n",
    "\n",
    "            print(\"Counterfactual 2-column probability:\", predict_fn(cf_sample))\n",
    "            \n",
    "            # Show the numerical difference\n",
    "            changes = cf_sample[0] - x_test_sample[0]\n",
    "            print(\"\\nDifference between CF and original sample:\")\n",
    "            for col, diff in zip(X_test.columns, changes):\n",
    "                print(f\"{col}: {diff:.3f}\")\n",
    "        else:\n",
    "            print(\"No counterfactual found within the specified parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was run multiple times, this was another of the counterfactuals given:\n",
    "\n",
    "*** COUNTERFACTUAL #1 ***\n",
    "\n",
    "Sample index: 0, Actual label: 1, Predicted: 0\n",
    "\n",
    "--- Counterfactual Explanation ---\n",
    "\n",
    "Original 2-column probability: [[0.64625597 0.353744 ]]\n",
    "\n",
    "Counterfactual feature values (scaled):\n",
    "\n",
    "array([[ 0.82737726, -1.394982 , 1.6170563 , 2.1170812 , -0.64842165,\n",
    "-0.73769516, 0.73769516, 2.074505 , 0.58823454, -1.6147097 ,\n",
    "1.3070657 ]], dtype=float32)\n",
    "\n",
    "Counterfactual 2-column probability: [[0.75010574 0.24989426]]\n",
    "\n",
    "Difference between CF and original sample:\n",
    "\n",
    "Pclass: 0.000\n",
    "\n",
    "Age: -1.395\n",
    "\n",
    "SibSp: 1.184\n",
    "\n",
    "Parch: 1.349\n",
    "\n",
    "Fare: -0.307\n",
    "\n",
    "Sex_female: -0.000\n",
    "\n",
    "Sex_male: 0.000\n",
    "\n",
    "Embarked_C: -0.000\n",
    "\n",
    "Embarked_Q: 0.896\n",
    "\n",
    "Embarked_S: -0.000\n",
    "\n",
    "Embarked_nan: 1.354\n",
    "\n",
    "\n",
    "*** COUNTERFACTUAL #2 ***\n",
    "\n",
    "Sample index: 4, Actual label: 1, Predicted: 0\n",
    "\n",
    "--- Counterfactual Explanation ---\n",
    "\n",
    "Original 2-column probability: [[0.54528 0.45472002]]\n",
    "\n",
    "Counterfactual feature values (scaled):\n",
    "\n",
    "array([[ 0.82737726, -1.2068506 , 0.43296716, -0.4736736 , -0.422202 ,\n",
    "1.3555735 , -1.3555735 , 2.074505 , 0.4825647 , 0.6193064 ,\n",
    "2.7697735 ]], dtype=float32)\n",
    "\n",
    "Counterfactual 2-column probability: [[0.79656625 0.20343377]]\n",
    "\n",
    "Difference between CF and original sample:\n",
    "\n",
    "Pclass: 0.000\n",
    "\n",
    "Age: 0.001\n",
    "\n",
    "SibSp: 0.000\n",
    "\n",
    "Parch: -0.000\n",
    "\n",
    "Fare: -0.000\n",
    "\n",
    "Sex_female: -0.000\n",
    "\n",
    "Sex_male: 0.000\n",
    "\n",
    "Embarked_C: -0.000\n",
    "\n",
    "Embarked_Q: 0.790\n",
    "\n",
    "Embarked_S: 2.234\n",
    "\n",
    "Embarked_nan: 2.817\n",
    "\n",
    "\n",
    "Output Explanation:\n",
    "Counterfactual #1 (Sample index: 0, Actual label: 1, Predicted: 0) In this example, the\n",
    "model originally assigns a probability of approximately 64.63% to class 0 (and 35.37% to\n",
    "class 1). Several features are then adjusted—most notably, Age decreases substantially\n",
    "(by -1.395 in scaled units), while SibSp (number of siblings/spouses) and Parch (number\n",
    "of parents/children) both increase. Additionally, there are changes in Embarked_Q and\n",
    "Embarked_nan. After these modifications, the model’s probability for class 0 rises to\n",
    "about 75.01%, moving further away from predicting the correct label of 1. This indicates\n",
    "that these specific adjustments to the features cause the model to become even more\n",
    "confident in the incorrect prediction. It suggests that age and the number of family\n",
    "members travelling (as encoded in SibSp and Parch) may be influential in pushing the\n",
    "prediction toward non-survival under this particular counterfactual setting.\n",
    "\n",
    "Counterfactual #2 (Sample index: 4, Actual label: 1, Predicted: 0) Here, the original\n",
    "probabilities are roughly 54.53% for class 0 versus 45.47% for class 1—still an incorrect\n",
    "prediction, though the model is slightly less certain compared with Counterfactual #1.\n",
    "The counterfactual modifies the feature representation of passenger embarkation, with\n",
    "notable jumps in Embarked_Q, Embarked_S, and Embarked_nan. Despite these changes,\n",
    "the probability for class 0 increases further to approximately 79.66%. This outcome\n",
    "indicates that shifts in certain embarkation features, under the current model, do not\n",
    "bring the prediction closer to the correct label for this sample but instead reinforce the\n",
    "model’s belief that the passenger did not survive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 b\n",
    "\n",
    "Counterfactual explanations are vital because they tell us how to alter specific features in a model’s input so that its prediction changes to a desired outcome. When we see how even small changes in passenger attributes (for instance, lowering their age or increasing their fare) flip the prediction from “died” to “survived,” we gain insights into what the model deems crucial for its decision.\n",
    "\n",
    "In debugging models, counterfactuals help us pinpoint problematic behaviours and potential biases. If the counterfactual requires unrealistic feature shifts—such as setting the fare far above any real-world range—then our model may be over-reliant on that feature, or it might not generalise well. We can use this knowledge to refine data preprocessing or adjust hyperparameters, ensuring our model bases decisions on more sensible factors.\n",
    "\n",
    "Counterfactuals can direct real-world interventions from a decision-making perspective. For instance, if a passenger's survival probability increases significantly with a slight increase in fare, this indicates that socioeconomic position (as measured by fare) has a significant impact on the model. Managers, legislators, or end users can then evaluate the fairness or realism of these elements. Counterfactuals essentially assist stakeholders in understanding how to modify inputs in a meaningful way, increasing the transparency of model outputs and enabling more informed choices in practical situations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
