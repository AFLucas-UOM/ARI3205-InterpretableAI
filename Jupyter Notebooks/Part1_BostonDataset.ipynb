{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project ARI3205 Interpretable AI for Deep Learning Models *(Part 1.1)*\n",
    "---\n",
    "\n",
    "**Name:** Andrea Filiberto Lucas  \n",
    "**ID No:** 0279704L\n",
    "\n",
    "---\n",
    "\n",
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[92m✔\u001b[0m] Library 'tensorflow' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'scikit-learn' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'matplotlib' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'seaborn' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'pandas' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'numpy' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'scipy' is already installed.\n",
      "[\u001b[92m✔\u001b[0m] Library 'alibi' is already installed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the libraries from the text file\n",
    "with open('../Libraries/Part1_Lib.json', 'r') as file:\n",
    "    libraries = json.load(file)\n",
    "\n",
    "# ANSI escape codes for colored output\n",
    "GREEN = \"\\033[92m\"  # Green text\n",
    "RED = \"\\033[91m\"    # Red text\n",
    "RESET = \"\\033[0m\"   # Reset to default color\n",
    "\n",
    "# Function to check and install libraries\n",
    "def check_and_install_libraries(libraries):\n",
    "    for lib, import_name in libraries.items():\n",
    "        try:\n",
    "            # Attempt to import the library\n",
    "            __import__(import_name)\n",
    "            print(f\"[{GREEN}✔{RESET}] Library '{lib}' is already installed.\")\n",
    "        except ImportError:\n",
    "            # If import fails, try to install the library\n",
    "            print(f\"[{RED}✖{RESET}] Library '{lib}' is not installed. Installing...\")\n",
    "            %pip install {lib}\n",
    "\n",
    "# Execute the function to check and install libraries\n",
    "check_and_install_libraries(libraries)\n",
    "\n",
    "# Import necessary libraries for data analysis and modeling\n",
    "import pandas as pd                                                                 # Data manipulation and analysis                #type: ignore\n",
    "import numpy as np                                                                  # Numerical computations                        #type: ignore\n",
    "import matplotlib.pyplot as plt                                                     # Data visualization                            #type: ignore\n",
    "import seaborn as sns                                                               # Statistical data visualization                #type: ignore\n",
    "import statsmodels.formula.api as smf                                               # Statistical models                            #type: ignore\n",
    "from sklearn.model_selection import train_test_split                                # Train-test split                              #type: ignore\n",
    "from tensorflow.keras.models import Sequential                                      # Neural network model                          #type: ignore\n",
    "from tensorflow.keras.layers import Dense                                           # Neural network layers                         #type: ignore                                                               \n",
    "from tensorflow.keras.optimizers import Adam                                        # Neural network optimizer                      #type: ignore\n",
    "from sklearn.preprocessing import StandardScaler                                    # Data scaling                                  #type: ignore\n",
    "from sklearn.impute import SimpleImputer                                            # Missing value imputation                      #type: ignore\n",
    "from sklearn.inspection import PartialDependenceDisplay, permutation_importance     # Feature importance                            #type: ignore\n",
    "from sklearn.neural_network import MLPRegressor                                     # Neural network model                          #type: ignore\n",
    "from sklearn.metrics import mean_squared_error                                      # Model evaluation                              #type: ignore\n",
    "from alibi.explainers import ALE, plot_ale                                          # ALE plots                                     #type: ignore\n",
    "\n",
    "# Suppress specific warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information on Boston Housing Dataset\n",
    "\n",
    "*https://www.kaggle.com/datasets/altavish/boston-housing-dataset/data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'../Datasets/Boston/Boston.csv' dataset loaded successfully.\n",
      "\n",
      "Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     486 non-null    float64\n",
      " 1   ZN       486 non-null    float64\n",
      " 2   INDUS    486 non-null    float64\n",
      " 3   CHAS     486 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      486 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    int64  \n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    486 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
      "count  486.000000  486.000000  486.000000  486.000000  506.000000  506.000000   \n",
      "mean     3.611874   11.211934   11.083992    0.069959    0.554695    6.284634   \n",
      "std      8.720192   23.388876    6.835896    0.255340    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.081900    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.253715    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.560263   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
      "count  486.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.518519    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
      "std     27.999513    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
      "25%     45.175000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
      "50%     76.800000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
      "75%     93.975000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "            LSTAT        MEDV  \n",
      "count  486.000000  506.000000  \n",
      "mean    12.715432   22.532806  \n",
      "std      7.155871    9.197104  \n",
      "min      1.730000    5.000000  \n",
      "25%      7.125000   17.025000  \n",
      "50%     11.430000   21.200000  \n",
      "75%     16.955000   25.000000  \n",
      "max     37.970000   50.000000  \n"
     ]
    }
   ],
   "source": [
    "# Define the filename\n",
    "filename = '../Datasets/Boston/Boston.csv'\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    boston_data = pd.read_csv(filename)\n",
    "    print(f\"'{filename}' dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{filename}' was not found. Please ensure it is in the correct directory.\")\n",
    "    exit()\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Error: The file '{filename}' is empty.\")\n",
    "    exit()\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"Error: There was a problem parsing '{filename}'. Please check the file format.\")\n",
    "    exit()\n",
    "\n",
    "# Dataset insights\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(boston_data.info())\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(boston_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (404, 13)\n",
      "Test data shape: (102, 13)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = boston_data.drop(columns=['MEDV'])  # Features\n",
    "y = boston_data['MEDV']  # Target\n",
    "\n",
    "# Handle missing values with mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X.columns)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 645.2300 - mae: 23.4115 - val_loss: 524.8203 - val_mae: 21.4135\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 574.2705 - mae: 21.9858 - val_loss: 497.6118 - val_mae: 20.7998\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 536.5518 - mae: 21.2740 - val_loss: 461.5500 - val_mae: 19.9766\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 497.8069 - mae: 20.2422 - val_loss: 413.4614 - val_mae: 18.8347\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.4543 - mae: 18.9435 - val_loss: 352.3260 - val_mae: 17.2758\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 379.2853 - mae: 17.4573 - val_loss: 282.6457 - val_mae: 15.2887\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 289.0721 - mae: 15.0384 - val_loss: 210.0639 - val_mae: 12.9400\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 208.8056 - mae: 12.2309 - val_loss: 141.5309 - val_mae: 10.2660\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159.2571 - mae: 10.2924 - val_loss: 92.3218 - val_mae: 7.8376\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.0053 - mae: 8.4607 - val_loss: 63.4123 - val_mae: 6.1021\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 83.9556 - mae: 7.1975 - val_loss: 48.6223 - val_mae: 5.2081\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74.1939 - mae: 6.7037 - val_loss: 39.4831 - val_mae: 4.6419\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 51.5087 - mae: 5.6977 - val_loss: 34.5831 - val_mae: 4.2519\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.9480 - mae: 5.1391 - val_loss: 31.4680 - val_mae: 3.9955\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.6388 - mae: 4.8660 - val_loss: 29.9379 - val_mae: 3.8558\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.3427 - mae: 4.4203 - val_loss: 28.7189 - val_mae: 3.7407\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.0933 - mae: 4.1620 - val_loss: 28.1382 - val_mae: 3.7624\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6879 - mae: 3.8019 - val_loss: 27.7926 - val_mae: 3.7364\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.4489 - mae: 3.9058 - val_loss: 27.2892 - val_mae: 3.7180\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.5218 - mae: 3.9389 - val_loss: 26.8414 - val_mae: 3.7165\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.9665 - mae: 3.5673 - val_loss: 26.7154 - val_mae: 3.7335\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.2355 - mae: 3.4453 - val_loss: 26.0181 - val_mae: 3.6747\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.0856 - mae: 3.5292 - val_loss: 25.4482 - val_mae: 3.6080\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.2500 - mae: 3.3759 - val_loss: 25.1409 - val_mae: 3.5856\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8982 - mae: 3.3982 - val_loss: 24.8466 - val_mae: 3.5469\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.5300 - mae: 3.5148 - val_loss: 24.5958 - val_mae: 3.5323\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.8930 - mae: 3.4315 - val_loss: 23.8198 - val_mae: 3.4721\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.5142 - mae: 3.3481 - val_loss: 23.5160 - val_mae: 3.4297\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.1113 - mae: 3.2289 - val_loss: 23.3202 - val_mae: 3.4183\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.2748 - mae: 3.1178 - val_loss: 22.5675 - val_mae: 3.3499\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0852 - mae: 3.1456 - val_loss: 22.1608 - val_mae: 3.2999\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.5065 - mae: 3.1268 - val_loss: 22.0234 - val_mae: 3.3032\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.7292 - mae: 3.2364 - val_loss: 22.0559 - val_mae: 3.3047\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.6718 - mae: 2.9324 - val_loss: 21.8734 - val_mae: 3.2968\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.1475 - mae: 3.0871 - val_loss: 21.9366 - val_mae: 3.3021\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.7531 - mae: 3.0058 - val_loss: 21.0269 - val_mae: 3.2254\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.6437 - mae: 2.8546 - val_loss: 20.5257 - val_mae: 3.1772\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.4615 - mae: 2.9173 - val_loss: 20.1423 - val_mae: 3.1338\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.9975 - mae: 2.9938 - val_loss: 20.5060 - val_mae: 3.1821\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.4879 - mae: 3.0326 - val_loss: 20.4924 - val_mae: 3.1888\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.1819 - mae: 2.8665 - val_loss: 20.3685 - val_mae: 3.1735\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.7325 - mae: 2.9290 - val_loss: 20.3516 - val_mae: 3.1746\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3950 - mae: 2.9394 - val_loss: 20.1186 - val_mae: 3.1518\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.9459 - mae: 2.8671 - val_loss: 19.8091 - val_mae: 3.1226\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.4252 - mae: 2.7961 - val_loss: 19.5076 - val_mae: 3.0971\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.5811 - mae: 2.7467 - val_loss: 19.0409 - val_mae: 3.0573\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.9192 - mae: 2.7470 - val_loss: 18.9722 - val_mae: 3.0442\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.6132 - mae: 2.7322 - val_loss: 19.1208 - val_mae: 3.0632\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.9107 - mae: 2.9656 - val_loss: 18.6390 - val_mae: 3.0229\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.5608 - mae: 2.5465 - val_loss: 18.3175 - val_mae: 2.9891\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.1552 - mae: 2.3130  \n",
      "Test Loss: 16.7229, Test MAE: 2.4515\n"
     ]
    }
   ],
   "source": [
    "# Build the feed-forward neural network\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Model - MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surrogate Model Mean Squared Error: 12.7475\n"
     ]
    }
   ],
   "source": [
    "# Train an MLPRegressor as a surrogate model\n",
    "surrogate_model = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)\n",
    "surrogate_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the surrogate model\n",
    "y_pred = surrogate_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Surrogate Model Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Dependence Plots (PDP)\n",
    "def plot_pdp(features):\n",
    "    print(\"\\nGenerating PDP for features:\", features)\n",
    "    fig, ax = plt.subplots(1, len(features), figsize=(12, 6), constrained_layout=True)\n",
    "    for i, feature in enumerate(features):\n",
    "        PartialDependenceDisplay.from_estimator(\n",
    "            surrogate_model,  # The trained surrogate model (MLPRegressor)\n",
    "            X_train,          # Training data\n",
    "            features=[feature],  # Single feature for PDP\n",
    "            kind=\"average\",   # PDP only\n",
    "            ax=ax[i] if len(features) > 1 else ax,\n",
    "            grid_resolution=50,\n",
    "        )\n",
    "        ax[i].set_title(f\"PDP for {feature}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Conditional Expectation (ICE) Plots\n",
    "def plot_ice(features):\n",
    "    print(\"\\nGenerating ICE for features:\", features)\n",
    "    fig, ax = plt.subplots(1, len(features), figsize=(12, 6), constrained_layout=True)\n",
    "    for i, feature in enumerate(features):\n",
    "        PartialDependenceDisplay.from_estimator(\n",
    "            surrogate_model,  # The trained surrogate model (MLPRegressor)\n",
    "            X_train,          # Training data\n",
    "            features=[feature],  # Single feature for ICE\n",
    "            kind=\"both\",      # PDP and ICE\n",
    "            ax=ax[i] if len(features) > 1 else ax,\n",
    "            grid_resolution=50,\n",
    "        )\n",
    "        ax[i].set_title(f\"ICE and PDP for {feature}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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